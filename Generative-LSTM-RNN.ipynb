{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import traceback\n",
    "import pdb\n",
    "from os import path\n",
    "from datetime import datetime\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### hyperparameters ### (are there more???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = \"/Users/jamesledoux/Documents/data_exploration/author_files/shakespeare\"\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### prepare the data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text info: len 163631, type <type 'str'>\n",
      "Total Unique Chars:  47\n"
     ]
    }
   ],
   "source": [
    "text = open(file_path).read().lower()\n",
    "len_text = len(text)\n",
    "print 'Text info: len {}, type {}'.format(len_text, type(text))\n",
    "\n",
    "# Get Unique chars from text\n",
    "chars = sorted(list(set(text)))\n",
    "len_chars = len(chars)\n",
    "print 'Total Unique Chars: ', len_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up translation dicts\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number sequences:  54517\n",
      "Vectorizing...\n",
      "Space X: 204984048 Bytes\n",
      "Space_y: 2562411 Bytes\n"
     ]
    }
   ],
   "source": [
    "maxlen = 80\n",
    "# step through text file\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    end_index = i + maxlen\n",
    "    sentences.append(text[i: end_index])\n",
    "    next_chars.append(text[end_index])\n",
    "print 'Total number sequences: ', len(sentences)\n",
    "\n",
    "# Start making your sparse matrices\n",
    "print 'Vectorizing...'\n",
    "X = np.zeros((len(sentences), maxlen, len_chars), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len_chars), dtype=np.bool)\n",
    "\n",
    "# Check space complexity\n",
    "space_X = sys.getsizeof(X)\n",
    "space_y = sys.getsizeof(y)\n",
    "print 'Space X: {} Bytes'.format(space_X)\n",
    "print 'Space_y: {} Bytes'.format(space_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build the final matrix of sequences to be used in training\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function for building the model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(X_shape_1, X_shape_2, y_shape, prev_epoch_counter):\n",
    "    # define the LSTM model via our old code - No callbacks for now\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, input_shape=(X_shape_1, X_shape_2), return_sequences=True))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(y_shape, activation='softmax'))\n",
    "    \n",
    "    # Check if weights file exists, should not exist only for first run\n",
    "    file_path = 'char_training/model_weights_' + str(prev_epoch_counter) + '.h5'\n",
    "    print 'File path of model weights: ', file_path\n",
    "    if path.isfile(file_path):\n",
    "        print 'found file, loading weights... '\n",
    "        model.load_weights(file_path)\n",
    "    else:\n",
    "        print '.h5 file not found'\n",
    "    # Compile and return model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function for saving model weights ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_history(history):\n",
    "    print \"Saving History\"\n",
    "    with open('character-training_history.json', 'w') as f:\n",
    "        json.dump(history.history, f)\n",
    "    print 'History Saved'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sampling function for output generation... credit to fchollet on this ### (can I figure out what this does + explain it a little?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "The sample() method below is by fchollet\n",
    "This is a helper function to sample an index from a probability array\n",
    "Adjusting the normalizing factor of the predictions is something we never thought\n",
    "of doing, but it has a huge effect on the generated output. \n",
    "Log(preds) -> normalize -> exp(preds) -> normalize again -> Multinomial dist where pval = preds\n",
    "Never would have thought of this.\n",
    "\"\"\"\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_shape_1, X_shape_2 = X.shape[1], X.shape[2]\n",
    "y_shape = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### function for generating output as we train ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_output(model, len_text, maxlen, len_chars, char_indices, indices_char, text, epoch):\n",
    "    stdout = sys.stdout\n",
    "    output_path = 'char_lstm_output_files/lstm_output_text_{:02d}.txt'.format(epoch)\n",
    "    sys.stdout = open(output_path, 'w')\n",
    "    start_index = random.randint(0, len_text - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print '\\n Output for Epoch {:02d} with diversity {}'.format(epoch, diversity)\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print 'Seed: \"' + sentence + '\" \\n'\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(1000):\n",
    "            x = np.zeros((1, maxlen, len_chars))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "    sys.stdout = stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### train the model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting Epoch 0 ... \n",
      "File path of model weights: "
     ]
    }
   ],
   "source": [
    "full_start_time = datetime.now()\n",
    "for epoch in range(num_epochs):\n",
    "    print '\\n Starting Epoch {} ... '.format(epoch)\n",
    "    model = build_model(X_shape_1, X_shape_2, y_shape, epoch - 1)\n",
    "    # Fit for for 1 epoch only\n",
    "    start_time = datetime.now()\n",
    "    # Commented out callbacks for now\n",
    "    history = model.fit(X, y, validation_split=0.20, nb_epoch=1, batch_size=512, verbose=1)\n",
    "    model_total_time = datetime.now() - start_time\n",
    "    print \"training time: \" + str(model_total_time)\n",
    "    save_history(history)\n",
    "\n",
    "    # Save the weights from the training\n",
    "    print '\\n Saving weights ...'\n",
    "    model_weights = 'char_training/model_weights_' + str(epoch) + '.h5'\n",
    "    model.save_weights(model_weights)\n",
    "    print 'Weights Saved'\n",
    "    gen_output(model, len_text, maxlen, len_chars, char_indices, indices_char, text, epoch)\n",
    "    print '\\n Finished output of Epoch: {}'.format(epoch)\n",
    "\n",
    "total_time = datetime.now() - full_start_time\n",
    "print \"Semi-total Run Time: \" + str(model_total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
